wandb_track: false
weight_decay: 0.0005
batch_size: 32
lr: 1e-4
max_steps: 40000
train_seed: 42
val_freq: 2000
ckpt_every_n_steps: 2000
gradient_clip_val: 10 # 0 means no clipping
loss_fn: mse
devices: 1  # Number of GPUs to use for training
strategy: auto  # DDP strategy for multi-GPU training
